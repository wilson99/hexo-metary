---
title: 机器学习实战
top: false
cover: true
toc: true
mathjax: true
date: 2021-1-3
password:
summary:
tags: 
	Scikit-Learn
	Keras
	TensorFlow
categories: Machine Learning
---

# 第一部分	机器学习的基础知识
## 第1章	机器学习概览
### 是否在人类监督下进行训练
#### 1. 有监督学习
* k-近邻算法
* 线性回归
* 逻辑回归
* 支持向量机（SVM）
* 决策树和随机森林
* 神经网络

#### 2. 无监督学习
* 聚类算法
  * k-均值算法
  * DBSCAN
  * 分层聚类分析（HCA）
* 异常检测和新颖性检测
  * 单类SVM
  * 孤立森林
* 可视化和降维
  * 主成分分析（PCA）
  * 核主成分分析
  * 局部线性嵌入（LLE）
  * t-分布随机近邻嵌入（t-SNE）
* 关联规则学习
  * Apriori
  * Eclat

#### 3. 半监督学习
#### 4. 强化学习
### 是否可以动态的进行增量学习
#### 1. 批量学习
#### 2. 增量学习：在线学习，核外学习（离线）
### 是简单的将新数据点和已知的数据点进行匹配，还是对训练数据进行模式检测然后建立一个预测模型
#### 1. 基于实例的学习
#### 2. 基于模型的学习
### 特征工程
#### 1. 特征选择
#### 2. 特征提取
#### 3. 创建新特征（收集新数据或通过特征组合）
### 过拟合
#### 1. 简化模型
#### 2. 减少数据噪声
#### 3. 收集更多数据
### 欠拟合
#### 1. 选择带有更多参数、更强大的模型
#### 2. 提供更好的特征集（特征工程）
#### 3. 减少模型中的约束（如：减少正则化超参数）
### 测试集与验证集

## 第2章	端到端的机器学习项目
### 选择性能指标
#### 均方根误差 RMSE
$$RMSE(X, h) = \sqrt{\sum_{i=1}^m(h(x^{(i)})-y^{(i)})^2}$$
#### 平方绝对误差 MAE
$$MAE(X, h) = \sqrt{\sum_{i=1}^m|h(x^{(i)})-y^{(i)}|}$$
### 微调模型
#### 网格搜索 GridSearchCV
#### 随机搜索 RandomizedSearchCV

## 第3章	分类
### 二元分类器 SGDClassifier
### 交叉验证 cross_val_score()
### 混淆矩阵 confusion_matrix()
### 精度 = $\frac{TP}{TP+FP}$
### 召回率 = $\frac{TP}{TP+FN}$
### F1 = $\frac{2}{\frac{1}{精度}+\frac{1}{召回率}}=2*\frac{精度*召回率}{精度+召回率}=\frac{TP}{TP+\frac{FN+FP}{2}}$
### 精度/召回率权衡
### ROC曲线，AUC为曲线下的面积
当正类非常少见或者你更关注假正类而不是假负类时，应该选择召回率（PR）曲线，反之则是ROC曲线。
### 多类分类器
#### 算法：随机森林，朴素贝叶斯
#### 有多种策略可以使用几个二元分类器（如支持向量机分类器或线性分类器）实现多类分类
#### 多标签分类（KNeighbersClassifier支持多标签分类）
#### 多输出分类
分类和回归之间的界限有时很模糊，多输出系统也不仅仅限于分类任务，可以让一个系统给每个实例输出多个标签，同时包括类标签和值标签。

## 第4章	训练模型

## 第5章	支持向量机

## 第6章	决策树

## 第7章	集成学习和随机森林

## 第8章	降维

## 第9章	无监督学习技术

# 第二部分	神经网络与深度学习
## 第10章	Keras人工神经网络简介

## 第11章	训练深度神经网络

## 第12章	使用TensorFlow自定义模型和训练

## 第13章	使用TensorFlow加载和预处理数据

## 第14章	使用卷积神经网络的深度计算机视觉

## 第15章	使用RNN和CNN处理序列

## 第16章	使用RNN和注意力机制进行自然语言处理

## 第17章	使用自动编码器和GAN的表征学习和生成学习

## 第18章	强化学习

## 第19章	大规模训练和部署TensorFlow模型
